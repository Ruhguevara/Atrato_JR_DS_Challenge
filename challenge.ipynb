{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2176836-bc09-43be-8e31-9c122c669754",
   "metadata": {},
   "source": [
    "<hr style=\"border:0.02in solid gray\"> </hr>\n",
    "\n",
    "<center> <font color= #847ACC> <h1> Atrato JR Data Scientist Challenge <center></h1> </font>\n",
    "    \n",
    "<center> <font color= #847ACC> <font size = 4>  RubÃ©n HernÃ¡ndez Guevara <center> </font> \n",
    "<br>\n",
    "<center> Repository: https://github.com/Ruhguevara/Atrato_JR_DS_Challenge\n",
    "<br>\n",
    "<br>\n",
    "<hr style=\"border:0.02in solid gray\"> </hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2323ea4-197f-4e3c-be54-7f473550d13b",
   "metadata": {},
   "source": [
    "<font color= #847ACC> <h1> Problem: </h1> </font>\n",
    "\n",
    "**Introduction:** \n",
    "\n",
    "In this challenge, you will tackle the task of predicting the probability that a student will pass a grade. As a data scientist, you must choose and apply the best algorithm to build a predictive model. \n",
    "\n",
    "**Context:** \n",
    "\n",
    "Imagine you are part of a data science team working for an educational institution. The team is tasked with developing a predictive model that can assist in identifying students who are likely to pass or fail the grade. Such a model can provide valuable insights into student performance and help in designing targeted interventions to support struggling students.\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "- Load and explore the dataset\n",
    "- Visualize the relationships:\n",
    "    - Bivariate analysis.\n",
    "    - Correlation matrix.\n",
    "    - Others\n",
    "- Normalize or standardize features if necessary.\n",
    "- Build a predictive model.\n",
    "- Train the model.\n",
    "- Assess the model's performance using metrics such as accuracy, confusion matrix, and classification report.\n",
    "- Interpret the results of the model.\n",
    "- Communicate conclusions regarding the founding relationships.\n",
    "- Provide actionable recommendations based on the\n",
    "\n",
    "**Dataset:** \n",
    "\n",
    "https://archive.ics.uci.edu/dataset/320/student+performance\n",
    "\n",
    "- Share a diagram that shows an en-to- end pipeline data science project from experimentation to a productive environment.\n",
    "- You can use https://www.drawio.com/\n",
    "\n",
    "**Extra Points:**\n",
    "- How to integrate DVC in the pipeline.\n",
    "- How to integrate MLFLOW in the pipeline.\n",
    "\n",
    "Can you explain and give eofes about the following concepts:\n",
    "- Encapsulation\n",
    "- Abstraction\n",
    "- Inheritance\n",
    "- Polymorphis\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99483e8-f138-411c-b6b8-89379899122a",
   "metadata": {},
   "source": [
    "<h1> <font color= #847ACC> Content </h1>\n",
    "<a id=\"IND\"></a>\n",
    "\n",
    "<b> I.  [Exploratory Data Analysis and Data Cleaning](#EDA) </b><br>\n",
    "- [ ] [Exploration](#EXP)\n",
    "- [ ] [Missing Values](#MISS)\n",
    "- [ ] [Duplicates](#DUPLI)\n",
    "- [ ] [Unique Value](#UNIQ)\n",
    "- [ ] [Correlation](#CORR)\n",
    "\n",
    "<b> II. [Statistics](#EST)</b><br>\n",
    "- [ ] [Measures of Central Tendency & Variability](#MTCV)\n",
    "- [ ] [Distributions](#DIST)\n",
    "- [ ] [Class Balance](#BAL)\n",
    "    \n",
    "<b> III. [Pre-processing](#PREP)</b><br>\n",
    "- [ ] [Scaling](#SCAL)\n",
    "- [ ] [Sampling](#SAMP)\n",
    "\n",
    "<b> IV. [Models](#MODELOS)</b><br>\n",
    "- [ ] [Logistic Regression](#RL)\n",
    "  - [ ] [Metrics](#MRL)\n",
    "  - [ ] [Decile Analysis](#ADE)\n",
    "- [ ] [XGBoost](#XGB)\n",
    "    \n",
    "<b> V. [Conclusions](#CONC)</b><br>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5235337b-2fa2-4c7b-bb11-5e4571782221",
   "metadata": {},
   "source": [
    "### How to run the notebook:\n",
    "\n",
    "First, it is suggested to create a virtual environment and activate it with the following command:\n",
    "\n",
    "`python -m venv venv` -> `source venv/Scripts/activate` \n",
    "\n",
    "After activating the virtual env, install the requirements:\n",
    "\n",
    "`pip install -r requirements.txt`\n",
    "\n",
    "Then, execute the following code to start the notebook:\n",
    "\n",
    "`jupyter notebook`\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce07898f-4877-4c6f-85a8-1f252c7d9210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display_html\n",
    "\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, roc_curve, confusion_matrix, make_scorer, roc_auc_score\n",
    "\n",
    "\n",
    "# Aditional Libraries\n",
    "from collections import Counter\n",
    "from EDA import DataExplorer as de # I made this script\n",
    "import time\n",
    "\n",
    "# Configurations\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "matplotlib.style.use('seaborn')\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fd186b-0b34-44da-baf8-ee5c27880975",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd165170",
   "metadata": {},
   "source": [
    "847ACC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c99cb1e",
   "metadata": {},
   "source": [
    "<h1> <font color= #847ACC> Exploratory Data Analysis and Cleaning </h1>\n",
    "<a id=\"EDA\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91273dbd",
   "metadata": {},
   "source": [
    "<div style=\"border-radius:14px; border:#847ACC solid; padding: 15px; background-color: #FFFFFF; font-size:100%; text-align:left\">\n",
    "<h3 align=\"left\"><font color='#847ACC'>ðŸ’¡ Parquet:</font></h3>\n",
    "    \n",
    "Parquet as a data storage reduces file size, processing time, and associated costs, which translates to saved money, time, and storage.\n",
    "    \n",
    "<center><img src=\"imgs/parquet.png\" width=\"650\" height=\"200\"></center>\n",
    "    \n",
    "Source: <br>\n",
    "<a href=\"https://parquet.apache.org/docs/\"> Apache Parquet Documentation </a> <br>\n",
    "<a href=\"https://www.databricks.com/glossary/what-is-parquet\"> General Description </a> <br>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b667fb42",
   "metadata": {},
   "source": [
    "<div style=\"border-radius:14px; border:#847ACC solid; padding: 15px; background-color: #FFFFFF; font-size:100%; text-align:left\">\n",
    "<h3 align=\"left\"><font color='#847ACC'>ðŸ’¡</font></h3>\n",
    "\n",
    "**``The 2.0 version of pandas introduces the Apache Arrow backend, which allows for a more efficient way of storing data in memory:``**\n",
    "\n",
    "For example:\n",
    "- int64 $\\rightarrow$ int64[pyarrow]\n",
    "- float64 $\\rightarrow$ double[pyarrow]\n",
    "- string $\\rightarrow$ string[pyarrow]\n",
    "    \n",
    "For the first part of the project, I will work with the pyarrow backend. \n",
    "\n",
    "Another alternative for improving data reading speed could be `PySpark`, `Polars` or the recent `cuDF` from NVDIA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ad2f44-8cec-4fc8-b6e1-eecb728f7db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.read_parquet('data/student-por.parquet', engine = \"pyarrow\", dtype_backend = \"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98093ed5",
   "metadata": {},
   "source": [
    "<div style=\"border-radius:14px; border:#847ACC solid; padding: 15px; background-color: #FFFFFF; font-size:100%; text-align:left\">\n",
    "<h3 align=\"left\"><font color='#847ACC'>ðŸ’¡</font></h3>\n",
    "\n",
    "The time required to load the data is actually higher than using a .csv with the traditional backend, \n",
    "it is beause of the data size, in larger datasets, the power of using .parquet and pyarrow is huge!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a7bdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"approved\"] = [1 if df[\"G3\"][i] > 12 else 0 for i in range(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a8f70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cf09c3",
   "metadata": {},
   "source": [
    "[<div style=\"text-align:center\"><img src=\"imgs/arrow.png\" width=\"10\" height=\"5\"></div>](#IND)\n",
    "<h2> <font color= #847ACC> Exploration </h2>\n",
    "<a id=\"EXP\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24b1baa-67c1-48ad-9828-f3d481fc0644",
   "metadata": {},
   "source": [
    "## Qualitative Research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427cae9f-b9f8-4810-b8c8-53813c5497c1",
   "metadata": {},
   "source": [
    "### PISA Study\n",
    "\n",
    "PISA \n",
    "(Programme for International Student Assessment) is an international study of student performance in\r\n",
    "reading, mathematics and science. The last study is from 2018 and there's a new study every three years.\r\n",
    "A small fraction of all students of age 15 is randomly chosen to participa\n",
    "\n",
    "- The test has a mean score of 487 for girls and 492 for boys, and Portugal is slightly above the average with 488 for girls and 497 for boys. This suggest that ``sex may be a factor affecting performance`` (Based on PISA scores in 2018).\n",
    "\n",
    "- Socio-economic status explained 17% of the variation in mathematics performance for the\r\n",
    "Portuguese participants. This suggests that factors like parent's education and job, address, parental\r\n",
    "status, school, family support, going out with friends and the use of alcohol may be factors thatff\n",
    "a\u001bects student performanc\n",
    "\n",
    "Sources:\n",
    "\n",
    "https://data.oecd.org/pisa/mathematics-performance-pisa.htm\n",
    "\n",
    "https://www.oecd.org/pisa/publications/PISA2018_CN_PRT.pdfes.te."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25b2a9e-08cf-461f-a3dd-891c1f01cc0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c72c5c1-f85d-4749-9752-fc4ac97779b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea82926-4008-42c3-9d9e-a6c4ab37c463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d03005-2224-4a57-80c8-14502538adb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eec8ae1-9ed0-4e5f-bbd1-94c8d4f4979e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ed45f5-90c8-4af4-a225-eb4e2d4fb1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8175be-2c16-44fa-af59-1b95828d979b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7524bd56-9c98-455b-a072-0047ad85995f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46634c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec980aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_html(df.head(2), df.sample(2), df.tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb45099",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df[\"approved\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5822484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shape_1 = df.shape\n",
    "print(df_shape_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101c8734",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"G2\"] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7007a7d4",
   "metadata": {},
   "source": [
    "[<div style=\"text-align:center\"><img src=\"imgs/arrow.png\" width=\"10\" height=\"5\"></div>](#IND)\n",
    "<h2> <font color= #847ACC> Missing Values </h2>\n",
    "<a id=\"MISS\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4f88a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = df.isnull().sum().sort_values(ascending = False)\n",
    "percent = (df.isnull().sum()/df.isnull().count()*100).sort_values(ascending = False)\n",
    "pd.concat([total, percent], axis=1, keys=['Total', '%']).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbccc0f",
   "metadata": {},
   "source": [
    "<div style=\"border-radius:14px; border:#847ACC solid; padding: 15px; background-color: #FFFFFF; font-size:100%; text-align:left\">\n",
    "<h3 align=\"left\"><font color='#847ACC'>ðŸ’¡ Insights:</font></h3>\n",
    "    \n",
    "It doesn't seem like there are any missing values. If there are any, there are several techniques for data imputation:\n",
    "\n",
    "- Mean\n",
    "- Mode\n",
    "- Models\n",
    "- Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37875bc4",
   "metadata": {},
   "source": [
    "[<div style=\"text-align:center\"><img src=\"imgs/arrow.png\" width=\"10\" height=\"10\"></div>](#IND)\n",
    "<h2> <font color= #847ACC> Duplicates </h2>\n",
    "<a id=\"DUPLI\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ab8507",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Duplicates: \", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f319dee",
   "metadata": {},
   "source": [
    "<div style=\"border-radius:14px; border:#847ACC solid; padding: 15px; background-color: #FFFFFF; font-size:100%; text-align:left\">\n",
    "<h3 align=\"left\"><font color='#847ACC'>ðŸ’¡ Insights:</font></h3>\n",
    "    \n",
    "There are not duplicate data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6af78c9",
   "metadata": {},
   "source": [
    "[<div style=\"text-align:center\"><img src=\"imgs/arrow.png\" width=\"10\" height=\"5\"></div>](#IND)\n",
    "<h2> <font color= #847ACC> Unique Values </h2>\n",
    "<a id=\"UNIQ\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883175f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    print(f\"Unique value in {i}:\")\n",
    "    print(df[i].unique(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91393c8a",
   "metadata": {},
   "source": [
    "[<div style=\"text-align:center\"><img src=\"imgs/arrow.png\" width=\"10\" height=\"5\"></div>](#IND)\n",
    "<h2> <font color= #847ACC> Correlation </h2>\n",
    "<a id=\"CORR\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c91ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = df.select_dtypes(include=['string']).columns\n",
    "numerical_columns = df.select_dtypes(include=['number']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce52b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(df[numerical_columns].corr().round(1), text_auto=True, aspect=\"auto\", color_continuous_scale=px.colors.sequential.Blues)\n",
    "fig.layout.height = 600\n",
    "fig.layout.width = 1050\n",
    "fig.update_coloraxes(showscale=False)\n",
    "fig.update_layout(\n",
    "    title_text=\"Correlation Map\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9c05f4",
   "metadata": {},
   "source": [
    "<h2> <font color= #847ACC> Statistics</h2>\n",
    "<a id=\"EST\"></a>\n",
    "    \n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e13813",
   "metadata": {},
   "source": [
    "[<div style=\"text-align:center\"><img src=\"imgs/arrow.png\" width=\"10\" height=\"5\"></div>](#IND)\n",
    "<h3> <font color= #847ACC> Measures of Central Tendency & Variability </h3>\n",
    "<a id=\"MTCV\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a99639",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "de.generate_data_description_table(df[numerical_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2739874f",
   "metadata": {},
   "source": [
    "[<div style=\"text-align:center\"><img src=\"imgs/arrow.png\" width=\"10\" height=\"5\"></div>](#IND)\n",
    "<h2> <font color= #847ACC> Distributions </h2>\n",
    "<a id=\"DIST\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f8b2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df[\"age\"], bins=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b533247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_columns = len(df[numerical_columns].columns)\n",
    "# num_plots_per_row = 3\n",
    "# num_rows = (num_columns + num_plots_per_row - 1) // num_plots_per_row\n",
    "\n",
    "# fig, axes = plt.subplots(num_rows, num_plots_per_row, figsize=(15, 5*num_rows))\n",
    "\n",
    "# for i, col in enumerate(df[numerical_columns].columns):\n",
    "#     ax = axes[i // num_plots_per_row, i % num_plots_per_row]\n",
    "#     sns.distplot(df[numerical_columns][col], ax=ax)\n",
    "#     ax.set_title(col)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"imgs/distributions.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83841def",
   "metadata": {},
   "source": [
    "[<div style=\"text-align:center\"><img src=\"imgs/arrow.png\" width=\"10\" height=\"5\"></div>](#IND)\n",
    "<h2> <font color= #847ACC> Class Balance </h2>\n",
    "<a id=\"BAL\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0851b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count = pd.value_counts(df['approved'], sort = True).sort_index()\n",
    "class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b61b4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Class Composition - Pie Plot\n",
    "fig = go.Figure(data=[go.Pie(labels=['Not approved', 'approved'], \n",
    "                                    values=class_count, \n",
    "                                    pull=[0.05, 0, 0], \n",
    "                                    opacity=0.85)])\n",
    "fig.update_layout(\n",
    "    title_text=\"Class Composition\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10503b6e",
   "metadata": {},
   "source": [
    "<div style=\"border-radius:14px; border:#847ACC solid; padding: 15px; background-color: #FFFFFF; font-size:100%; text-align:left\">\n",
    "<h3 align=\"left\"><font color='#847ACC'>ðŸ’¡ Insights:</font></h3>\n",
    "    \n",
    "a\n",
    "\n",
    "- Subsampling\n",
    "- Oversampling\n",
    "- Class Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69037124",
   "metadata": {},
   "source": [
    "[<div style=\"text-align:center\"><img src=\"imgs/arrow.png\" width=\"10\" height=\"5\"></div>](#IND)\n",
    "<h1> <font color= #847ACC> Pre-processing </h1>\n",
    "<a id=\"PREP\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4269919c-d5ca-45ba-ae86-cb7545b26dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df[\"sex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e9b570-436b-4f69-95eb-6ade97343948",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636a5893-2ffc-4485-801d-5382ebf33bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61888aff-0f9c-4723-8455-e8c612f23fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "\n",
    "for column in df.select_dtypes(include=['object', 'category', 'string']).columns:\n",
    "    df_test[column] = labelencoder.fit_transform(df_test[column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd87156-0266-4f81-ae97-ecfac982b8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc86dc5-41fd-407f-8df8-1f005d99bae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2cfce21",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5857c87b",
   "metadata": {},
   "source": [
    "<h1> <font color= #847ACC> Models </h1>\n",
    "<a id=\"MODELOS\"></a>\n",
    "\n",
    "_\"All models are wrong, but some are useful\"_ \\\n",
    "â€” George Box\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1928bd",
   "metadata": {},
   "source": [
    "[<div style=\"text-align:center\"><img src=\"imgs/arrow.png\" width=\"10\" height=\"5\"></div>](#IND)\n",
    "<h2> <font color= #847ACC> Logistic Regression </h2>\n",
    "<a id=\"RL\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2c5f7f",
   "metadata": {},
   "source": [
    "<div style=\"border-radius:14px; border:#847ACC solid; padding: 15px; background-color: #FFFFFF; font-size:100%; text-align:left\">\n",
    "<h3 align=\"left\"><font color='#ECB431'>ðŸ’¡ Justification:</font></h3>\n",
    "    \n",
    "- Logistic Regression is a relatively simple algorithm; it transforms a linear input into a probability (in the range of 0-1) using the Sigmoid function:\n",
    "\n",
    "$$S(x) = \\frac{1}{1+e^{-X\\beta}}$$\n",
    " \n",
    "Where $X$ is the set of predictor features, and $\\beta$ is the corresponding weight vector. Computing $S(x)$ yields a probability indicating whether an observation should be classified as `1` or `0`.\n",
    "<br>\n",
    "\n",
    "- It is highly interpretable due to its output (probabilities), making it easier to explain to a non-technical audience compared to other models.\n",
    "\n",
    "- Computationally, it requires less computational power compared to more complex models such as Neural Networks or Decision Trees.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235dcfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as array the features and the classes\n",
    "X = df_test.iloc[:, 0:-1].values\n",
    "y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289bfb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data after Oversampling and Undersampling\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(X, y, test_size = 0.35, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2590432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression with Subsampling, Oversampling and Class Weights\n",
    "LR = LogisticRegression(random_state = 0, C=10, penalty= 'l2', class_weight = {0: 1, 1:2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae805a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR.fit(x_train1, y_train1) #.predict(X).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4944875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR.fit(x_train1, y_train1) #.predict(X).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d8336a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit is for GS to optimize for that metric.\n",
    "# Increasing the search space for the weights helps the model focus on fraud cases.\n",
    "\n",
    "def grids(search_space: np.ndarray, opt_metric: str, cv: int):\n",
    "    \n",
    "    grid_ = GridSearchCV(\n",
    "    estimator = LogisticRegression(max_iter = 500),\n",
    "    param_grid = {'class_weight': [{0: 1, 1:v} for v in search_space]},\n",
    "    scoring = {'precision': make_scorer(precision_score), 'recall': make_scorer(recall_score), 'f1': make_scorer(f1_score)},\n",
    "    refit = opt_metric, \n",
    "    return_train_score = True,\n",
    "    cv = cv,\n",
    "    n_jobs = -1\n",
    "    )\n",
    "    \n",
    "    return grid_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3339626",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_prec = grids(np.linspace(1, 20, 30), opt_metric = 'precision', cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b760991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rec = grids(np.linspace(1, 20, 30), opt_metric = 'recall', cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e0a968",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_f1 = grids(np.linspace(1, 20, 30), opt_metric = 'f1', cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2b77e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_prec.fit(x_train1, y_train1)\n",
    "grid_prec.best_params_['class_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9798fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Â¡Â¡Â¡Notice how a model focused on detecting more frauds (recall) assigns a lot of weight to '1'.!!!\n",
    "grid_rec.fit(x_train1, y_train1)\n",
    "grid_rec.best_params_['class_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1777c6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_f1.fit(x_train1, y_train1)\n",
    "grid_f1.best_params_['class_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437be1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the results of the GridSearch\n",
    "# Originally, it uses 'mean_test_score' for optimization, with the default score being Accuracy.\n",
    "# In a highly imbalanced case, it's not a good choice to use it as a reference metric.\n",
    "# It will be changed to precision, recall, or f1, as appropriate. They are added to the GridSearch.\n",
    "\n",
    "df = pd.DataFrame(grid_prec.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871304d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['param_class_weight', 'params', \n",
    "    'mean_test_precision', 'mean_train_precision', \n",
    "    'mean_test_recall', 'mean_train_recall',\n",
    "    'mean_test_f1', 'mean_train_f1']]\n",
    "\n",
    "# These results are from the first fit, that is, with optimized precision, which is why weights 0:1 and 1:1 are chosen.\n",
    "# Notice how the precision is decreasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba2f146",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 4))\n",
    "for score in ['mean_test_recall', 'mean_test_precision', 'mean_test_f1']:\n",
    "    plt.plot([_[1] for _ in df['param_class_weight']],\n",
    "             df[score],\n",
    "             label = score)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb388aa",
   "metadata": {},
   "source": [
    "- The class weights are on the 'x' axis, and the 3 scores are on the 'y' axis.\n",
    "- If you are looking for balance, the crossing point is the optimal weight (f1_score).\n",
    "- If you are looking to maximize one, its peak point is the goal.\n",
    "    - For 'precision', it's with a 1:1 weight ratio.\n",
    "    - For 'recall', it's a higher weight ratio, between 1:15 and 1:20.\n",
    "    - For 'f1', it's with a 1:1 weight ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09a88ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unlike .predict, .predict_proba returns the probabilities without the threshold criterion.\n",
    "probs = grid_f1.predict_proba(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd18f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is an array with the probabilities for class 0 and 1, where these are complementary.\n",
    "# We will work with the probabilities of class 1.\n",
    "print(probs.shape)\n",
    "probs_1 = probs[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661e3fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test1, probs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef905ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curve\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Plot the random guess line\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f992369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(label, prediction, train=True):\n",
    "    if train:\n",
    "        clf_report = pd.DataFrame(classification_report(label, prediction, output_dict=True))\n",
    "        print(\"Train Result:\\n==========================================================================\")\n",
    "        print(\"__________________________________________________________________________\")\n",
    "        print(f\"Classification Report:\\n{clf_report}\")\n",
    "        print(\"__________________________________________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(label, prediction)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        clf_report = pd.DataFrame(classification_report(label, prediction, output_dict=True))\n",
    "        print(\"Test Result:\\n==========================================================================\")        \n",
    "        print(\"__________________________________________________________________________\")\n",
    "        print(f\"Classification Report:\\n{clf_report}\")\n",
    "        print(\"__________________________________________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(label, prediction)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b9cef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confussion Matrix Function\n",
    "def CM(y_test, y_pred):\n",
    "    \n",
    "    # Confussion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "    counts = [value for value in cm.flatten()]\n",
    "    percentages = ['{0:.2%}'.format(value) for value in cm.flatten()/np.sum(cm)]\n",
    "    labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in zip(names, counts, percentages)]\n",
    "    labels = np.asarray(labels).reshape(2, 2)\n",
    "    \n",
    "    sns.heatmap(cm, annot = labels, cmap = 'Blues', fmt ='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af7bfc4",
   "metadata": {},
   "source": [
    "<h3> <font color= #847ACC> Case 1- Optimizing Precision </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ee1bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_train_pred = grid_prec.predict(x_train1)\n",
    "prec_test_pred = grid_prec.predict(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1679cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_score(y_train1, prec_train_pred, train=True)\n",
    "print_score(y_test1, prec_test_pred, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc9f192",
   "metadata": {},
   "outputs": [],
   "source": [
    "CM(y_test1, prec_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63265344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580c14aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b38c7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc9f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224ca90d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96baba3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd4deba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d2bbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier()\n",
    "xgb_clf.fit(x_train1, y_train1, eval_metric='aucpr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e83c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = xgb_clf.predict(x_train1)\n",
    "y_test_pred = xgb_clf.predict(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f52a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_xgb = xgb_clf.predict_proba(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be65dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_score(y_train1, y_train_pred, train=True)\n",
    "print_score(y_test1, y_test_pred, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f0990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CM(y_test1, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa52decf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed33e48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df291f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f945f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810622cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8032c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e2a2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daec561",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total runtime: {total_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
